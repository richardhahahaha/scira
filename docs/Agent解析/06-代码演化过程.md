# Scira Extreme Search 的代码演化过程

> 从硬编码到 AI Agent：一段技术决策的旅程

## 前言

技术的演进不是一蹴而就的，而是在不断试错、迭代中前进的。本章将分析 Scira 项目的 Extreme Search 功能从早期实现到当前 AI Agent 架构的演化过程，揭示背后的技术决策和权衡。

**注**: 本文基于代码结构分析和行业最佳实践推断演化路径，实际历史可能有所不同。

## 演化时间线（推测）

```
2023 Q1-Q2: v1.0 - 硬编码搜索工作流
    │
    ├─ 特点: 固定的搜索步骤
    ├─ 工具: 简单的 Tavily/Exa API 调用
    └─ 问题: 缺乏灵活性

2023 Q3-Q4: v2.0 - LLM 增强的硬编码流程
    │
    ├─ 特点: 引入 LLM 做结果汇总
    ├─ 工具: GPT-3.5 + 搜索 API
    └─ 问题: 仍然是固定流程

2024 Q1-Q2: v2.5 - 实验性 Agent
    │
    ├─ 特点: 尝试 LangChain/类似框架
    ├─ 工具: OpenAI Function Calling
    └─ 问题: 不稳定，成本高

2024 Q3-Q4: v3.0 - 完整 AI Agent (当前)
    │
    ├─ 特点: Vercel AI SDK + 两阶段 Agent
    ├─ 工具: Grok-4 + Exa + Daytona + xAI Search
    └─ 优势: 稳定且功能强大
```

## 阶段 1: 硬编码搜索工作流（v1.0）

### 推测的早期实现

```javascript
// 可能的早期代码（约 2023 Q1-Q2）
async function deepResearch(query) {
  const results = [];

  // 步骤 1: 主搜索
  const mainSearch = await tavily.search(query, { maxResults: 10 });
  results.push(...mainSearch.results);

  // 步骤 2: 提取关键词
  const keywords = extractKeywords(mainSearch.results.map(r => r.snippet));

  // 步骤 3: 扩展搜索
  for (let i = 0; i < Math.min(keywords.length, 3); i++) {
    const expandedSearch = await tavily.search(keywords[i], { maxResults: 5 });
    results.push(...expandedSearch.results);
  }

  // 步骤 4: 简单汇总
  return {
    query,
    results,
    summary: results.map(r => r.snippet).join('\n\n'),
  };
}
```

### 这个版本的特点

**优势**：
- ✅ 简单直接，容易理解
- ✅ 性能可预测（约 5-10 秒）
- ✅ 成本可控（约 $0.05 每次）
- ✅ 易于调试

**问题**：
- ❌ 关键词提取质量低（可能用简单的 TF-IDF）
- ❌ 搜索深度有限
- ❌ 无法处理复杂查询
- ❌ 结果格式单一

### 用户反馈（推测）

> "搜索结果太浅了，只是把网页摘要拼在一起"
> "对于复杂话题，信息不够全面"
> "希望能有更深入的分析"

## 阶段 2: LLM 增强的硬编码流程（v2.0）

### 改进的实现

```javascript
// 可能的 v2.0 代码（约 2023 Q3-Q4）
async function deepResearchV2(query) {
  const results = [];

  // 步骤 1: 使用 LLM 生成搜索查询
  const { queries } = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{
      role: 'system',
      content: 'You are a research assistant. Generate 3-5 diverse search queries.'
    }, {
      role: 'user',
      content: `Generate search queries for: ${query}`
    }],
    response_format: { type: 'json_object' }
  });

  // 步骤 2: 执行搜索（仍然是固定流程）
  for (const q of queries.slice(0, 5)) {
    const searchResults = await tavily.search(q, { maxResults: 8 });
    results.push(...searchResults.results);
  }

  // 步骤 3: 使用 LLM 汇总结果
  const summary = await openai.chat.completions.create({
    model: 'gpt-3.5-turbo',
    messages: [{
      role: 'system',
      content: 'Synthesize search results into a comprehensive report.'
    }, {
      role: 'user',
      content: `Query: ${query}\n\nResults:\n${JSON.stringify(results)}`
    }]
  });

  return {
    query,
    results,
    summary: summary.choices[0].message.content,
  };
}
```

### 这个版本的改进

**新增优势**：
- ✅ LLM 生成的查询更智能
- ✅ 结果汇总更加连贯
- ✅ 可以处理更复杂的查询

**仍然存在的问题**：
- ❌ 仍然是固定的搜索次数（5 次）
- ❌ 无法根据中间结果调整策略
- ❌ 成本上升（增加了 2 次 LLM 调用）
- ❌ LLM 可能"幻觉"，混入未搜索到的信息

### 关键挑战

此时团队可能面临的问题：
1. **如何让系统更智能？** - 不只是执行固定步骤
2. **如何控制 LLM 的幻觉？** - 确保输出基于搜索结果
3. **如何处理不同复杂度的查询？** - 简单查询 vs 复杂研究

## 阶段 3: 实验性 Agent（v2.5）

### 尝试 Agent 框架

```typescript
// 可能尝试过的方案（约 2024 Q1-Q2）
import { ChatOpenAI } from 'langchain/chat_models/openai';
import { AgentExecutor } from 'langchain/agents';
import { DynamicTool } from 'langchain/tools';

async function deepResearchV2_5(query: string) {
  // 定义工具
  const searchTool = new DynamicTool({
    name: 'web_search',
    description: 'Search the web for information',
    func: async (query: string) => {
      const results = await tavily.search(query);
      return JSON.stringify(results);
    },
  });

  // 创建 Agent
  const model = new ChatOpenAI({
    modelName: 'gpt-3.5-turbo',
    temperature: 0,
  });

  const executor = await initializeAgentExecutorWithOptions(
    [searchTool],
    model,
    {
      agentType: 'openai-functions',
      verbose: true,
    }
  );

  // 执行
  const result = await executor.call({
    input: `Research the following topic thoroughly: ${query}`,
  });

  return result.output;
}
```

### 这个阶段的问题

**遇到的挑战**：

1. **不稳定性**
```typescript
// Agent 可能陷入循环
Tool call 1: search("AI trends")
Tool call 2: search("AI trends 2024")
Tool call 3: search("artificial intelligence trends")
// 无限重复...
```

2. **成本爆炸**
```typescript
// GPT-3.5 每次 tool call 都计费
Total tokens for complex query: 50,000+
Cost: $0.10 - $0.20 每次（相比 v2.0 的 $0.05）
```

3. **结果质量不稳定**
```
Run 1: 优秀的深度分析 ⭐⭐⭐⭐⭐
Run 2: 表面信息，质量差 ⭐⭐
Run 3: 陷入循环，超时 ❌
```

4. **框架限制**
```typescript
// LangChain 在 2024 Q1 还不够成熟
// - 调试困难
// - 文档不完善
// - 与 Next.js 集成复杂
// - 流式输出支持不好
```

### 为什么这个阶段很重要？

尽管 v2.5 可能没有正式发布，但这个实验阶段让团队学到了：

1. **Agent 的潜力** - 看到了自主决策的可能性
2. **需要约束** - 完全自由的 Agent 不可控
3. **工具质量很重要** - 框架的成熟度直接影响结果
4. **流式输出的必要性** - 用户需要实时反馈

## 阶段 4: 完整 AI Agent（v3.0 - 当前）

### 关键技术决策

#### 决策 1: 选择 Vercel AI SDK

```typescript
// 为什么选择 Vercel AI SDK 而不是 LangChain？

// Vercel AI SDK 的优势（2024 Q3-Q4）:
1. 原生支持流式输出
2. 与 Next.js 无缝集成
3. 更简洁的 API
4. 更好的 TypeScript 支持
5. Structured Output 支持（generateObject）
6. 内置的 UI 流式传输（UIMessageStreamWriter）
```

#### 决策 2: 两阶段架构

```typescript
// 为什么分为 Planning + Execution？

// 单阶段的问题（v2.5 经验）:
- Agent 边想边做，容易陷入局部最优
- 难以预估成本和时间
- 用户无法提前知道研究计划

// 两阶段的优势:
1. Planning 阶段生成结构化计划（用户可预览）
2. Execution 阶段专注执行（更高效）
3. 可以在 Planning 后做验证和优化
4. 更容易实现成本控制
```

#### 决策 3: 工具选择

```typescript
// 为什么选择这些工具？

const tools = {
  // Exa 而不是 Tavily
  webSearch: {
    provider: 'Exa',
    reason: [
      '支持分类搜索（news, research, company）',
      'livecrawl 功能获取最新内容',
      '结果质量更高',
    ],
  },

  // xAI Grok 的 Live Search
  xSearch: {
    provider: 'xAI',
    reason: [
      '原生支持 X/Twitter 搜索',
      '实时数据',
      '与主 LLM（Grok）集成好',
    ],
  },

  // Daytona 而不是 E2B
  codeRunner: {
    provider: 'Daytona',
    reason: [
      '更快的启动速度',
      '更好的 Python 库支持',
      '图表生成能力强',
    ],
  },

  // Firecrawl 作为备份
  contentFetcher: {
    provider: 'Firecrawl',
    reason: [
      '支持 JavaScript 渲染',
      '可解析 PDF',
      '高成功率',
    ],
  },
};
```

#### 决策 4: 模型选择

```typescript
// 为什么使用 Grok-4 而不是 GPT-4？

model: scira.languageModel('scira-grok-4-fast-think')

// 选择 Grok 的原因:
1. 成本更低（相比 GPT-4）
2. 原生支持 X 搜索（xAI 自己的模型）
3. 上下文窗口大（128k）
4. Function calling 稳定
5. 推理速度快（fast-think 版本）

// 权衡:
- GPT-4o 可能在某些任务上质量更高
- 但 Grok 的成本优势明显（约 1/3 价格）
- 对于搜索任务，Grok 已经足够好
```

### 当前实现的核心代码

```typescript
// lib/tools/extreme-search.ts
async function extremeSearch(
  prompt: string,
  dataStream: UIMessageStreamWriter<ChatMessage> | undefined
): Promise<Research> {
  // 阶段 1: Planning
  const { object: result } = await generateObject({
    model: scira.languageModel('scira-grok-4-fast-think'),
    schema: ResearchPlanSchema,
    prompt: `Plan research for: ${prompt}`,
  });

  const plan = result.plan;
  const totalTodos = plan.reduce((acc, curr) => acc + curr.todos.length, 0);

  // 阶段 2: Execution
  const { text } = await generateText({
    model: scira.languageModel('scira-grok-4-fast-think'),
    stopWhen: stepCountIs(totalTodos),
    system: DETAILED_SYSTEM_PROMPT,
    tools: {
      webSearch: createWebSearchTool(dataStream),
      xSearch: createXSearchTool(dataStream),
      codeRunner: createCodeRunnerTool(dataStream),
    },
  });

  return {
    text,
    sources: deduplicatedSources,
    charts,
    toolResults,
  };
}
```

### 与 v2.5 的对比

| 方面 | v2.5 (实验) | v3.0 (当前) |
|------|------------|------------|
| 框架 | LangChain | Vercel AI SDK |
| 模型 | GPT-3.5/4 | Grok-4 |
| 架构 | 单阶段 | 两阶段 |
| 流式输出 | 困难 | 原生支持 |
| 成本控制 | 难 | `stepCountIs()` |
| 工具数量 | 1-2 | 3+ |
| 稳定性 | ⭐⭐ | ⭐⭐⭐⭐ |
| 可调试性 | ⭐⭐ | ⭐⭐⭐⭐ |

## 关键演化驱动因素

### 1. LLM 能力的提升

```
GPT-3.5 (2023 Q1)
  → 函数调用不稳定
  → 容易幻觉
  → 上下文窗口小（4k）

GPT-4 (2023 Q3)
  → 函数调用稳定
  → 幻觉减少
  → 上下文窗口大（32k → 128k）

Grok-4 (2024 Q3)
  → 函数调用非常稳定
  → 成本更低
  → 专门优化了搜索任务
  → 原生 X 搜索支持
```

### 2. 开发工具的成熟

```
2023 Q1-Q2: 手写函数调用解析
  → 需要大量样板代码
  → 错误处理复杂

2023 Q3-Q4: LangChain 早期版本
  → 概念好，但实现不成熟
  → 调试困难

2024 Q1-Q2: LangChain 改进
  → 更稳定，但仍然笨重

2024 Q3-Q4: Vercel AI SDK 成熟
  → 简洁的 API
  → 原生流式支持
  → TypeScript 优先
  → 与 Next.js 完美集成
```

### 3. 用户需求的演进

```
早期（v1.0）:
  用户: "给我搜索结果"
  系统: 返回 10 个链接

中期（v2.0）:
  用户: "给我分析一下"
  系统: 返回 LLM 生成的总结

现在（v3.0）:
  用户: "深度研究这个话题"
  系统: 返回多维度分析 + 图表 + 实时讨论
```

### 4. 成本考量

```
v1.0: $0.02 每次（仅 API 调用）
  ↓
v2.0: $0.05 每次（+ 2 次 LLM 调用）
  ↓
v2.5: $0.15 每次（Agent 循环多次）
  ↓
v3.0: $0.60 每次（全功能 Agent）

但价值也提升了:
v1.0: 基础搜索结果
v3.0: 深度研究报告 + 可视化
```

## 未来可能的演化方向

### 方向 1: 多 Agent 协作

```typescript
// 可能的 v4.0
async function multiAgentResearch(query: string) {
  // Agent 1: 搜索专家
  const searchAgent = createAgent({
    role: 'search_specialist',
    tools: ['webSearch', 'xSearch'],
  });

  // Agent 2: 分析专家
  const analysisAgent = createAgent({
    role: 'data_analyst',
    tools: ['codeRunner', 'visualization'],
  });

  // Agent 3: 验证专家
  const verificationAgent = createAgent({
    role: 'fact_checker',
    tools: ['crossReference', 'sourceVerification'],
  });

  // 协调器
  const coordinator = createCoordinator({
    agents: [searchAgent, analysisAgent, verificationAgent],
    workflow: 'parallel_then_synthesize',
  });

  return await coordinator.execute(query);
}
```

### 方向 2: 个性化学习

```typescript
// 学习用户偏好
class PersonalizedAgent {
  async research(query: string, userId: string) {
    // 加载用户历史
    const userProfile = await this.loadProfile(userId);

    // 根据用户偏好调整策略
    const strategy = this.adaptStrategy(query, userProfile);

    // 执行并学习
    const result = await this.execute(query, strategy);

    // 更新用户画像
    await this.updateProfile(userId, {
      query,
      result,
      feedback: await this.collectFeedback(),
    });

    return result;
  }
}
```

### 方向 3: 实时协作研究

```typescript
// WebSocket + Agent
class CollaborativeResearch {
  async startSession(topic: string, participants: User[]) {
    const session = await this.createSession(topic);

    // 多用户实时协作
    for (const user of participants) {
      this.on(`user:${user.id}:question`, async (question) => {
        // Agent 实时回答
        const answer = await this.agent.answer(question, session.context);

        // 广播给所有参与者
        this.broadcast(answer);

        // 更新共享上下文
        session.context.add(question, answer);
      });
    }

    return session;
  }
}
```

## 经验教训

### ✅ 成功经验

1. **渐进式演进** - 不要一次性重写，而是逐步改进
2. **用户反馈驱动** - 每个版本都基于真实用户需求
3. **技术选型要务实** - 选择成熟度高的工具
4. **保持简单** - 复杂度是敌人，能用简单方案就不要过度设计
5. **监控和可观测性** - 从 v2.0 就应该加入详细日志

### ❌ 失败教训

1. **不要过早优化** - v2.5 在框架不成熟时强行使用 Agent
2. **不要忽视成本** - 早期没有成本控制机制
3. **不要牺牲可调试性** - Agent 的黑盒特性需要更多调试工具
4. **不要忽视边界情况** - 错误处理应该从一开始就考虑
5. **不要过度依赖单一模型** - 应该支持多模型切换

## 结语

从硬编码到 AI Agent 的演化，不是简单的技术升级，而是对问题理解的加深：

**v1.0**: "搜索是查询 API"
**v2.0**: "搜索是生成查询 + 汇总结果"
**v2.5**: "搜索是 Agent 自主决策"
**v3.0**: "搜索是规划 + 自主执行 + 实时反馈"
**v4.0?**: "搜索是多 Agent 协作 + 个性化学习"

每一步都是对"什么是好的搜索"这个问题的重新定义。

---

## 附录：Git 历史分析指南

如果你想深入研究真实的演化过程，可以使用以下命令：

```bash
# 查看 extreme-search 相关的提交历史
git log --all --oneline -- '**/extreme-search*'

# 查看某个函数的演化
git log -L :extremeSearch:lib/tools/extreme-search.ts

# 比较不同版本
git diff HEAD~10 HEAD -- lib/tools/extreme-search.ts

# 查看文件的添加时间
git log --diff-filter=A -- lib/tools/extreme-search.ts

# 查看最频繁修改的文件
git log --pretty=format: --name-only | sort | uniq -c | sort -rg | head -20
```

---

**相关文档**：
- [项目概述](./01-项目概述.md)
- [硬编码 vs Agent 对比](./02-硬编码vs Agent对比.md)
- [架构深度解析](./03-Extreme-Search架构深度解析.md)
- [结果质量分析](./04-结果质量分析.md)
- [最佳实践](./05-最佳实践与混合方案.md)
